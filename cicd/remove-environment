#!/bin/bash

source "${CI_PROJECT_DIR}"/cicd/before-script

run_help() {
    echo ""
    echo "Purpose: Remove the environment from the nodes and cleanup the data left behind"
    echo ""
    echo "Expected User-defined Variables:"
    echo "  - AWS_KEY: Used for populating the variables.yml file"
    echo "  - AWS_SECRET: Used for populating the variables.yml file"
    echo "  - STACK_NAME: Used for populating the main.tf file"
    echo "  - DEPLOY_HOST_1: The first node in the cluster"
    echo "  - DEPLOY_HOST_2: The second node in the cluster"
    echo "  - DEPLOY_HOST_3: The third node in the cluster"
    echo ""
    echo "Failure Scenarios:"
    echo "  - The branch does not exist in GitLab anymore"
    echo "  - Required AWS credentials not provided to remove DNS entry"
    echo ""
}

if [[ -n "$1" || $1 == "-h" || $1 == "--help" || $1 == "help" ]]; then
    run_help
    exit 0
fi

waitforstop() {
    HOST=$1
    SERVICES=$(run_on_node "${HOST}" "docker ps --filter name=${STACK_NAME} --format '{{.Names}}' | wc -l")
    while [[ "${SERVICES}" -gt 0 ]]; do
        echo "There are still ${SERVICES} services running on ${HOST} for ${STACK_NAME}..."
        sleep 3
        SERVICES=$(run_on_node "${HOST}" "docker ps --filter name=${STACK_NAME} --format '{{.Names}}' | wc -l")
    done
}

prunevols() {
    HOST=$1
    VOLS=$(run_on_node "${HOST}" "docker volume ls --filter name=$STACK_NAME --format '{{.Name}}'")
    if [ -n "${VOLS}" ]; then
        if ! OUTPUT=$(run_on_node "${HOST}" "docker system prune -a -f; docker volume ls --filter name=$STACK_NAME --format '{{.Name}}' | xargs -n 1 docker volume rm"); then
            echo "Failed to remove one or more volumes from ${HOST} for ${VOLS}. ${OUTPUT}"
            exit 1
        fi
    fi
}

removemount() {
    HOST=$1
    # Remove the bind mount for the nagios user
    run_on_node "${HOST}" "sudo /usr/local/bin/pc-mount-logs ${STACK_NAME} /home/nagios/ --remove -v";

}

removesecrets() {
    echo "Deleting secrets for stack \"${STACK_NAME}\""
    # shellcheck disable=SC2207
    SECRET_IDS=($(run_on_node 1 "docker secret ls --filter name=\"${STACK_NAME}-\" --format \"{{.ID}}\""))
    # shellcheck disable=SC2207
    SECRETS=($(run_on_node 1 "docker secret ls --filter name=\"${STACK_NAME}-\" --format \"{{.ID}}: {{.Name}}\""))
    if [ ${#SECRETS[@]} -gt 0 ]; then
        echo "Secrets to delete : ${SECRETS[*]}"
        run_on_node 1 "docker secret rm ${SECRET_IDS[*]}"
    fi
}

main() {
    # Add .aws credentials
    envsubst < provision-dns-playbook/variables.yml | sponge provision-dns-playbook/variables.yml;

    # Replace STACK_NAME in env/prod/main.tf and create host file in provision-dns-playbook
    envsubst < dns-terraform/env/prod/main.tf | sponge dns-terraform/env/prod/main.tf;

    # Run playbook
    ansible-playbook provision-dns-playbook/decommission.yml;

    # Remove the alphabetic browse databases
    CONTAINER=$(run_on_node 1 "docker ps -q -f name=${STACK_NAME}-solr_cron");
    if [ -n "${CONTAINER}" ]; then
        run_on_node 1 "docker exec ${CONTAINER} rm -rf /mnt/shared/alpha-browse/${STACK_NAME}";
    fi

    # Cleanup volumes/networks/images/containers
    run_on_node 1 "docker stack rm ${STACK_NAME}-solr;
                docker stack rm ${STACK_NAME}-mariadb;
                docker stack rm ${STACK_NAME}-catalog;
                docker stack rm ${STACK_NAME}-monitoring;
                docker stack rm ${STACK_NAME}-internal;
                rm -rf $COMPOSE_PATH;"

    # Wait for the containers to stop now the services have been removed
    waitforstop 1;
    waitforstop 2;
    waitforstop 3;

    # Remove the nagios mount point
    removemount "${DEPLOY_HOST_1}";
    removemount "${DEPLOY_HOST_2}";
    removemount "${DEPLOY_HOST_3}";

    # Prune the volumes
    prunevols 1;
    prunevols 2;
    prunevols 3;

    removesecrets
}

before_script
if ! main; then
    echo "Failed to build ${COMPONENT}. Sleeping to add delay before potential retry.";
    sleep 3;
    exit 1;
fi;
